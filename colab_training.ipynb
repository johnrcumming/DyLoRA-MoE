{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4067c3e",
   "metadata": {},
   "source": [
    "# Colab Training Notebook: Generic PyTorch Pipeline\n",
    "\n",
    "This notebook sets up a full training workflow (data, model, training, validation, logging, export) suitable for Google Colab GPU runtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2140879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check Runtime Hardware (GPU/TPU Availability)\n",
    "import torch, platform, os\n",
    "print(f\"Python: {platform.python_version()}\")\n",
    "print(f\"Torch: {torch.__version__}\")\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device count:\", torch.cuda.device_count())\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"If you need a GPU: Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c40063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Install and Upgrade Dependencies\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q numpy matplotlib scikit-learn tensorboard tqdm\n",
    "import torch, torchvision, numpy as np, matplotlib\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "## 3. Mount Google Drive (Optional Persistence)\n",
    "USE_DRIVE = False  # set True to persist\n",
    "if USE_DRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    BASE_DIR = '/content/drive/MyDrive/colab_training_run'\n",
    "else:\n",
    "    BASE_DIR = '/content/training_run'\n",
    "\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "print(\"Base directory:\", BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d52ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Set Global Configuration (Paths, Hyperparameters, Seeds)\n",
    "import random, json, math, numpy as np, torch\n",
    "cfg = {\n",
    "    'batch_size': 128,\n",
    "    'lr': 3e-4,\n",
    "    'epochs': 15,\n",
    "    'seed': 42,\n",
    "    'data_dir': BASE_DIR + '/data',\n",
    "    'output_dir': BASE_DIR + '/outputs',\n",
    "    'num_workers': 2\n",
    "}\n",
    "\n",
    "def set_seed(seed:int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(cfg['seed'])\n",
    "os.makedirs(cfg['data_dir'], exist_ok=True)\n",
    "os.makedirs(cfg['output_dir'], exist_ok=True)\n",
    "print(cfg)\n",
    "# 5. Import Libraries\n",
    "import os, datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "print('Imports complete.')\n",
    "# 6. Download or Ingest Dataset (CIFAR10)\n",
    "train_val = datasets.CIFAR10(root=cfg['data_dir'], train=True, download=True)\n",
    "TEST = datasets.CIFAR10(root=cfg['data_dir'], train=False, download=True)\n",
    "classes = train_val.classes\n",
    "print('Classes:', classes)\n",
    "# 7. Inspect and Visualize Sample Data\n",
    "fig, axes = plt.subplots(2,5, figsize=(10,4))\n",
    "for ax in axes.flatten():\n",
    "    idx = random.randint(0, len(train_val)-1)\n",
    "    img, label = train_val[idx]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(classes[label])\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Create Train/Validation/Test Splits\n",
    "val_ratio = 0.1\n",
    "val_len = int(len(train_val)*val_ratio)\n",
    "train_len = len(train_val) - val_len\n",
    "train_ds, val_ds = random_split(train_val, [train_len, val_len], generator=torch.Generator().manual_seed(cfg['seed']))\n",
    "print(f'Train: {len(train_ds)}  Val: {len(val_ds)}  Test: {len(TEST)}')\n",
    "# 9. Build Dataset Pipeline (DataLoaders)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "common_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "train_ds.dataset.transform = train_transform\n",
    "val_ds.dataset.transform = common_transform\n",
    "TEST.transform = common_transform\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=cfg['batch_size'], shuffle=True, num_workers=cfg['num_workers'], pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=cfg['batch_size'], shuffle=False, num_workers=cfg['num_workers'], pin_memory=True)\n",
    "test_loader = DataLoader(TEST, batch_size=cfg['batch_size'], shuffle=False, num_workers=cfg['num_workers'], pin_memory=True)\n",
    "print('DataLoaders ready.')\n",
    "# 10. Define Model Architecture\n",
    "from torchvision.models import resnet18\n",
    "model = resnet18(weights=None, num_classes=len(classes))\n",
    "print(sum(p.numel() for p in model.parameters()), 'total params')\n",
    "\n",
    "# 11. Loss Function, Metrics, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg['lr'])\n",
    "\n",
    "def accuracy(outputs, targets):\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    return (preds == targets).float().mean().item()\n",
    "# 12. Mixed Precision (Automatic)\n",
    "use_amp = torch.cuda.is_available()\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "scaler = GradScaler(enabled=use_amp)\n",
    "print('AMP enabled:', use_amp)\n",
    "# 13. LR Scheduler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=cfg['epochs'])\n",
    "\n",
    "# 14 & 15. Training + Validation with Early Stopping\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "writer = SummaryWriter(log_dir=os.path.join(cfg['output_dir'], 'tb'))\n",
    "\n",
    "history = {k:[] for k in ['train_loss','val_loss','train_acc','val_acc','lr']}\n",
    "best_val_acc = 0.0\n",
    "patience = 5\n",
    "wait = 0\n",
    "for epoch in range(1, cfg['epochs']+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for batch in train_loader:\n",
    "        imgs, labels = batch\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast(enabled=use_amp):\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        running_loss += loss.item()*imgs.size(0)\n",
    "        running_acc += accuracy(outputs.detach(), labels)*imgs.size(0)\n",
    "    train_loss = running_loss/len(train_loader.dataset)\n",
    "    train_acc = running_acc/len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            with autocast(enabled=use_amp):\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()*imgs.size(0)\n",
    "            val_acc += accuracy(outputs, labels)*imgs.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc /= len(val_loader.dataset)\n",
    "\n",
    "    scheduler.step()\n",
    "    lr_current = scheduler.get_last_lr()[0]\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(lr_current)\n",
    "\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    writer.add_scalar('Acc/train', train_acc, epoch)\n",
    "    writer.add_scalar('Acc/val', val_acc, epoch)\n",
    "    writer.add_scalar('LR', lr_current, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} train_acc={train_acc:.3f} val_acc={val_acc:.3f} lr={lr_current:.2e}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        wait = 0\n",
    "        torch.save(model.state_dict(), os.path.join(cfg['output_dir'], 'best_model.pt'))\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print('Early stopping triggered.')\n",
    "            break\n",
    "\n",
    "writer.flush()\n",
    "# 16 & 17. Plot Training History\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1,2, figsize=(12,4))\n",
    "axs[0].plot(history['train_loss'], label='train'); axs[0].plot(history['val_loss'], label='val'); axs[0].set_title('Loss'); axs[0].legend()\n",
    "axs[1].plot(history['train_acc'], label='train'); axs[1].plot(history['val_acc'], label='val'); axs[1].set_title('Accuracy'); axs[1].legend()\n",
    "plt.show()\n",
    "# 18. Evaluate on Test Set\n",
    "best_path = os.path.join(cfg['output_dir'], 'best_model.pt')\n",
    "model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_labels.extend(labels.tolist())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print('Confusion matrix shape:', cm.shape)\n",
    "print(classification_report(all_labels, all_preds, target_names=classes))\n",
    "# 19. Save and Export Trained Model\n",
    "final_path = os.path.join(cfg['output_dir'], 'final_model.pt')\n",
    "torch.save(model.state_dict(), final_path)\n",
    "with open(os.path.join(cfg['output_dir'], 'config.json'),'w') as f: json.dump(cfg, f, indent=2)\n",
    "with open(os.path.join(cfg['output_dir'], 'classes.json'),'w') as f: json.dump(classes, f)\n",
    "print('Saved:', final_path)\n",
    "# 20. Load Saved Model and Run Inference\n",
    "loaded = resnet18(weights=None, num_classes=len(classes))\n",
    "loaded.load_state_dict(torch.load(best_path, map_location=device))\n",
    "loaded.eval()\n",
    "idxs = [random.randint(0, len(TEST)-1) for _ in range(5)]\n",
    "fig, axes = plt.subplots(1,5, figsize=(15,3))\n",
    "for ax, idx in zip(axes, idxs):\n",
    "    raw_img, lbl = TEST[idx]\n",
    "    img = common_transform(raw_img)\n",
    "    with torch.no_grad():\n",
    "        out = loaded(img.unsqueeze(0).to(device))\n",
    "        pred = out.argmax(1).item()\n",
    "    ax.imshow(raw_img)\n",
    "    ax.set_title(f\"P:{classes[pred]}\\nT:{classes[lbl]}\")\n",
    "    ax.axis('off')\n",
    "plt.show()\n",
    "# 21. Optional: Convert Model to ONNX\n",
    "sample_input = torch.randn(1,3,32,32, device=device)\n",
    "onxx_path = os.path.join(cfg['output_dir'], 'model.onnx')\n",
    "try:\n",
    "    torch.onnx.export(model, sample_input, onxx_path, input_names=['input'], output_names=['logits'], dynamic_axes={'input':{0:'batch'}, 'logits':{0:'batch'}}, opset_version=17)\n",
    "    print('Exported ONNX to', onxx_path)\n",
    "except Exception as e:\n",
    "    print('ONNX export failed (optional step):', e)\n",
    "# 22. Clean Up Session / Free GPU Memory\n",
    "del sample_input\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "print('Cleanup done.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
